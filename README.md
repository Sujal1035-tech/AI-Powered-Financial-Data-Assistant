# ğŸ¦ AI-Powered Financial Data Assistant

An intelligent financial assistant that uses semantic search and AI to help users query and analyze their financial transactions using natural language.

## ğŸŒŸ Features

- **AI-Generated Dummy Data**: Generates realistic financial transactions using Faker
- **Vector Embeddings**: Uses Sentence Transformers for semantic understanding
- **Semantic Search**: Natural language queries to find relevant transactions
- **AI Summarization**: Groq LLM provides intelligent insights and summaries
- **Interactive Dashboard**: Beautiful Streamlit UI with charts and analytics
- **REST API**: FastAPI backend for programmatic access

## ğŸ› ï¸ Tech Stack

- **Language**: Python 3.9+
- **Vector Database**: ChromaDB
- **Embeddings**: Sentence Transformers (all-MiniLM-L6-v2)
- **LLM**: Groq API (Llama 3)
- **Backend**: FastAPI
- **Frontend**: Streamlit
- **Data Generation**: Faker

## ğŸ“ Project Structure
```
financial-data-assistant/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ transactions.json          # Generated financial transactions
â”‚
â”œâ”€â”€ embeddings/
â”‚   â””â”€â”€ chroma_db/                 # ChromaDB vector store
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_generator.py          # Generate dummy transactions
â”‚   â”œâ”€â”€ embedding_service.py       # Create embeddings
â”‚   â”œâ”€â”€ vector_search_service.py   # ChromaDB operations
â”‚   â””â”€â”€ summarizer_service.py      # LLM summarization
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                     # FastAPI application
â”‚   â””â”€â”€ routes/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ search.py              # Search endpoints
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py                # Configuration
â”‚
â”œâ”€â”€ streamlit_app.py               # Streamlit UI
â”œâ”€â”€ requirements.txt               # Dependencies
â”œâ”€â”€ README.md                      # Documentation
â”œâ”€â”€ .env.example                   # Environment template
â””â”€â”€ .gitignore
```

## ğŸš€ Setup and Installation

### 1. Clone the Repository
```bash
git clone <your-repo-url>
cd financial-data-assistant
```

### 2. Create Virtual Environment
```bash
python -m venv venv

# On Windows
venv\Scripts\activate

# On Mac/Linux
source venv/bin/activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Configure Environment Variables

Create a `.env` file in the root directory:
```bash
cp .env.example .env
```

Edit `.env` and add your Groq API key:
```
GROQ_API_KEY=your_groq_api_key_here
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
CHROMA_DB_PATH=./embeddings/chroma_db
DATA_PATH=./data/transactions.json
```

**Get your free Groq API key**: [https://console.groq.com](https://console.groq.com)

### 5. Generate Dummy Data
```bash
python -m services.data_generator
```

This will create `data/transactions.json` with 450 transactions (3 users Ã— 150 transactions).

### 6. Initialize Vector Database
```bash
python -m services.vector_search_service
```

This will create embeddings and store them in ChromaDB.

## ğŸ¯ Usage

### Option : Streamlit UI (Recommended)
```bash
streamlit run streamlit_app.py
```

The app will open in your browser at `http://localhost:8501`

#### Features:
- **Search Tab**: Natural language queries
- **Dashboard Tab**: Visual analytics and charts
- **All Transactions Tab**: Filtered transaction view
- **Insights Tab**: AI-powered financial insights

### 1. Search Transactions
```bash
POST /api/search
```

**Request Body:**
```json
{
  "query": "Show my top 5 expenses in September",
  "user_id": "user_1",
  "top_k": 10,
  "summarize": true
}
```

**Response:**
```json
{
  "query": "Show my top 5 expenses in September",
  "transactions": [...],
  "count": 10,
  "summary": "You spent â‚¹12,300 on food in September..."
}
```

### 2. Get All Transactions
```bash
GET /api/transactions?user_id=user_1&limit=100
```

### 3. Get Insights
```bash
GET /api/insights?user_id=user_1
```

## ğŸ” Example Queries

Try these natural language queries:

- "Show all UPI transactions above â‚¹1000"
- "What's my biggest expense in August?"
- "How much did I spend on food last month?"
- "Show my top 5 expenses in September"
- "List all salary credits"
- "What did I spend on entertainment?"
- "Show transactions from Swiggy"
- "My total spending on shopping"

## ğŸ“Š Models & Configuration

### Embedding Model
- **Model**: sentence-transformers/all-MiniLM-L6-v2
- **Dimension**: 384
- **Use Case**: Semantic similarity search

### LLM Model
- **Provider**: Groq
- **Model**: Llama 3 (8B)
- **Use Case**: Transaction summarization and insights

### Vector Database
- **Database**: ChromaDB
- **Storage**: Persistent (local)
- **Similarity**: Cosine similarity

## ğŸ§ª Testing

### Using cURL
```bash
# Search transactions
curl -X POST "http://localhost:8000/api/search" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Show food expenses above 500 rupees",
    "user_id": "user_1",
    "top_k": 5,
    "summarize": true
  }'
```

## ğŸ“ˆ Sample Output

**Query:** "What are my top 3 expenses last month?"

**Response:**
```
Transactions:
- Amazon Purchase â€“ â‚¹2,500 â€“ 2024-09-15 [Shopping]
- Swiggy â€“ â‚¹1,300 â€“ 2024-09-10 [Food]
- Big Basket â€“ â‚¹1,150 â€“ 2024-09-18 [Shopping]

ğŸ’¬ Summary: You spent the most on shopping and food, totaling â‚¹4,950 in September. 
Your biggest single expense was an Amazon purchase of â‚¹2,500.
```

## ğŸ¨ Bonus Features Implemented

âœ… Date range filters using natural language
âœ… Visual charts of expenses by category
âœ… Multi-user support with isolated queries
âœ… RAG-based pipeline (Vector retrieval + LLM summarization)
âœ… Interactive Streamlit dashboard
âœ… Export functionality (CSV download)

## ğŸ› Troubleshooting

### Issue: "GROQ_API_KEY not found"
**Solution**: Make sure you've created a `.env` file with your Groq API key.

### Issue: "Collection not found"
**Solution**: Run the vector database initialization:
```bash
python -m services.vector_search_service
```

### Issue: "No module named 'sentence_transformers'"
**Solution**: Install all dependencies:
```bash
pip install -r requirements.txt
```



---

Built with â¤ï¸ using Python, ChromaDB, Groq & Streamlit
